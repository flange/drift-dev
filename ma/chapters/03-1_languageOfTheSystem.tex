\subsection{The Language of the System}
\label{LanguageOfTheSystem}

Rich Hickey is most widely known as the creater and
\textit{Benevolent Dictator for Life} (BDFL) \cite{bdfl} of
\textit{Clojure} \cite{clojure2008}, \cite{clojure2010},
\cite{clojure.org}, \cite{clojure-rationale},
a functional programming language and Lisp \cite{lisp86},
\cite{commonlisp90} dialect.
Clojure runs on the Java virtual machine to allow Java and Clojure interop
in order to utilize the extensive collection of already existing
Java libraries.

Clojure is therefor not a \textit{pure} \cite{pure}
functional programming language but should rather be considered a
pragmatist's compromise of having immutable data by default but
allowing for easy I/O and statefulness whenever neededed.

Although Clojure's \textit{front end} (its syntax) looks a lot like
Lisps syntax, which is notorious for its extensive use of
parenthesis, Clojure's \textit{back end} (its implementation)
focusses heavily on very modern features like
\textit{software transactional memory} \cite{stm} and
\textit{persistent data structures} \cite{persistentdatastructures}
aimed at highly concurrent programming.

Hickey himself has been promoting these features as necessary
upgrades to the object oriented view on programming in order to
fully utilize multicore architectures and is an avid
visitor of conferences of programming language design. He therefor has
a considerable collection of talks and lectures in which he explains
his rationale behind his design decisions \cite{hickey-talks},
\cite{hickey-bestof}.
\newline

One of his more relevant talks regarding the work presented here
is called ``The Language of the System''
\footnote{In the context of this talk and for the rest of the work presented
here the word \textit{system} does not mean \textit{low-level} or
\textit{bits and bytes} as in operating system but rather means
the system as a whole as from a bird's-eye view and more as
described by something like systems theory.}
held at \textit{Clojure Con} 2012 \cite{hickey-systemlang},
\cite{clojurecon}.
In it Hickey criticizes what has already been outlined in
chapter \ref{actorModel}, namely that distributed \textit{systems}
today are being built indirectly by programming individual units and
components and then running them simultaneously, hoping that a
distributed system will almost magically emerge but lacking any
description whatsoever of that system as a whole.

\begin{wrapfigure}{r}{0.5\textwidth}

  \includegraphics[width=0.5\textwidth]{systemlang.png}
  \caption{Slide-excerp from the talk ``The Language of the System'' by
          Rich Hickey that draws parallels between the composition of
          (local) programs and distributed systems.}
  \label{systemlang}

\end{wrapfigure}

The reason for this, he claims, is that the languages and tools
we use to build each individual component have been developed to
do exactly this: describe \textit{programs}, describe encapsulated
self-contained blocks of computation. They don't provide any
means of describing how to compose these components, because they
don't provide any primitives for how they \textit{communicate}.

As can be seen in Fig.\ref{systemlang} he draws parallels to how
we haven been building our programs in order to derive similar
properties for our system composition and description. For example
he proposes that the language of the system too, would have
primitives just like the programming languages that we have been
using so far. But instead of having primitives of computation like
built-in data types and arithmetic operators, in the systems context
these primitives would be primitives of \textit{communication} like
communication protocols or data formats. On top of which simple
core services need to be available in order to compose higher
level application logic, just like core libraries like
the GNU C library (glibc) \cite{glibc} or any other standard
library of any common programming language provide essential
building blocks for programmers to compose their programs.
\newline

So the relevance of this talk to the work presented here is, that
it sparked the question of whether or not it would be possible to
build such a composition language, a language of the system,
that allowed a global perspective without introducing global
state and how such a language would look like.
\newline

The other talk by Hickey which is relevant to this work and which
I would like to summarize here is called ``The value of values''
and was held at the GOTO Conference 2012 as well as the JaxConf 2012
\cite{vofv-infoq}, \cite{vofv-yt}, \cite{goto2012}, \cite{jax2012}.
Probably being his most famous talk, in it Hickey bootstraps his
views on programming and language design by putting
\textit{immutable data} at the center of programming and deriving
the advantages of core functional programming concepts from that.
He introduces two programming paradigms,
namely \textit{place-oriented programming} and
\textit{value-oriented programming}. A \textit{place} in Hickey's
view literally represents a place in reality. Something where
one can put things and where they reside. If one replaces the thing
that already resides in a place with some other thing, the
information of that exchange is never recorded. Places don't
record their exchange \textit{history} so to speak. Every exchange
\textit{overwrites} the current content of that place.
To the effect that the value received from querying a place
depends on the point in \textit{time} when the query was executed.
The value of the place is inherently intertwined with time, which
is what is generally known as \textit{state}.

This represent the bulk of programming language history. It
even represents the slots on the band of a Turing machine, which
can be overwritten by said Turing machine with symbols defined in
its alphabet. We have built hardware like memory and hard drives
but also our software like data bases and file systems
after this principle. They provide slots of storage which can
carry a value but can be overwritten so the new value replaces the
old and the value received from querying a place depends on the
moment in time of the query.

\begin{wrapfigure}{r}{0.6\textwidth}

  \includegraphics[scale=0.6, keepaspectratio]{sql.pdf}
  \caption{Place-orientation examplified by a SQL table, each cell
           being a place.}
  \label{sql}

\end{wrapfigure}

In order to examplify this concept, Fig.\ref{sql} shows a very
basic representation of what could be a \textit{SQL} table.
This table stores data using the schema of \textit{(ID, First Name,
Last Name, Email)} which is supposed to represent a registered
student. In Hickey's view, each cell of the table is a place, so
if a student were to change her email address only the cell containing
the email address would change, as shown in Fig.\ref{sql}b.
But changing an email address does not invalidate the fact that
there has been a point in time in which the student used the
old email address, just like electing a new president of a country
does not invalidate the fact that the country was once governed by
somebody else.

It is these \textit{facts} that in Hickey's view represent what is also
known as a \textit{value} because a value, once it exists, can never
change. One of the most used and perhaps most accessable examples of
values come from mathematics. The value '5' is just that, five. It
cannot be altered or changed in any way. Five is always five.
Mathematics allows for expressions like \textit{x = 5 + 1} which
binds the expression which uses two values and an operator to
the \textit{name} x. One could now \textit{evaluate} the subexpression
\textit{5 + 1} which would yield another value, namely '6', but that
would not change either the value '5' nor the value '1'. Five is always
five, even when used in compound expressions.

This is exactly what \textit{value-oriented programming} is about.
It treats \textit{data} as values, so data is \textit{immutable}
by default. Since data is immutable this means that it behaves
like facts: once created (once it happened) it stays true forever
and since operations on data can never change that data but only
create new data, it becomes easy to record the history of steps
that led to the creation of data. It's almost like one gets the
history of operations on data for free, once data is immutable
which is the direct opposite of place-oriented programming.
\newline

Both these approaches represent the extreme positions on a spectrum
of language and system design. Unfortunately though, both these
approaches in their basic form share a mutual problem: they don't scale.
Place-oriented systems are very \textit{space efficient} because
places are singletons, they are unique and there is only exactly
\textit{one} of each place. This means that all producers and
consumers or all readers and writers working on a place need to
be mutually excluded from doing so. Access to a place needs to
somehow be coordinated. One example for such coordination are
\textit{mutexes} (also called \textit{locks}). However, this means
that with an increasing number of accesses to a place, the
contention for that place increases and the time spent on coordinating
this access increases, especially if each logical operation needs
access to multiple places in order to complete successfully. So
place oriented systems scale in terms of space but not in terms of
time.

As already outlined, value-oriented systems implement the exact
opposite. Because values can never change, it is absolutely
safe to allow multiple access to a value, or give each accessor
its own copy. To stick with the mathematics example, it is common
to see multiple functions using the value '5' as one of their
input values. One calculating the square of its inputs the other
something completely different. Although both are working with
the same \textit{value} they are working with their own copies of it,
which don't have to updated or coordinated in any way, because
five is always five. The value cannot change. This means that there's
virtually no coordination overhead which allows value-oriented
systems to scale in time, but because multiple instances or copies
of the same value might need to exist, the system does not scale in
space.
\newline

So the choice every language or systems designer needs to make,
is which scalability bottleneck the system will be able to cope with.
Is space going to be the issue, so it is important to be space efficient
and feasible to pay for that efficiency with coordination overhead,
because contention will be sparse? Or is contention going to be the
issue, so that it is easier to supply enough space in order to keep
the coordination overhead to a minimum?

As I would like to argue, in the context of future
distributed systems,
the latter approach seems more appropriate because until now, we
have tried to simply port our place-oriented systems like file
systems and data bases into the distributed context and it didn't
seem to work out all that well. I argue that distributed systems
are not so much about place-efficient computation, but rather about
\textit{communication} and \textit{coordination}. Which means that
a value-oriented system will keep the overhead for these things to
a minimum and it is way easier to supply enough space, than to make
a place-oriented system scale in the distributed context.


